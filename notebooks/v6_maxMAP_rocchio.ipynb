{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rocchio & Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the lucene index with term vectors stored, the following retriever with Rocchio PRF can be run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this version 6 (v6) notebook, I aim to run a search for the max MAP for TFIDF term weights and report corresponding params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicFilePath = './trec6.xml'  # 50 queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse(topicFilePath)\n",
    "topics = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucene\n",
    "from org.apache.lucene.search import IndexSearcher\n",
    "from org.apache.lucene.index import DirectoryReader\n",
    "from org.apache.lucene.store import FSDirectory\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.search.similarities import BM25Similarity\n",
    "from org.apache.lucene.search.similarities import LMJelinekMercerSimilarity\n",
    "from org.apache.lucene.search.similarities import LMDirichletSimilarity\n",
    "from org.apache.lucene.analysis.en import EnglishAnalyzer\n",
    "from java.io import File\n",
    "\n",
    "from org.apache.lucene.search import BooleanQuery\n",
    "from org.apache.lucene.search import BooleanClause\n",
    "from org.apache.lucene.search import TermQuery\n",
    "from org.apache.lucene.search import BoostQuery\n",
    "from org.apache.lucene.index import Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jcc.JCCEnv at 0x7f918b461f90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this again if VM is not initialized already\n",
    "lucene.initVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = './index/'\n",
    "directory = FSDirectory.open(File(index_path).toPath())\n",
    "indexReader = DirectoryReader.open(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rocchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDNAME = 'CONTENT'       # Lucene index field name\n",
    "\n",
    "import math\n",
    "\n",
    "# calculating avgdl for queries. Used in BM25_query().\n",
    "analyzer = EnglishAnalyzer()\n",
    "query_lens = []\n",
    "for topic in topics:\n",
    "    queryKeywordsField = 'title'     # other fields are 'desc'and 'narr'\n",
    "    q = topic.find(queryKeywordsField).text.strip()\n",
    "    escaped_q = QueryParser(FIELDNAME, analyzer).escape(q)      # a few titles had '/' in them which \n",
    "                                                                # EnglishAnalyzer was not able to parse\n",
    "                                                                # without escaping those special characters\n",
    "    query = QueryParser(FIELDNAME, analyzer).parse(escaped_q)\n",
    "    query_terms = [term.strip()[len(FIELDNAME)+1:] for term in query.toString().split()]\n",
    "    query_lens.append(len(query_terms))\n",
    "avgdl_query = sum(query_lens)/len(query_lens)\n",
    "\n",
    "# calculating avgdl for the corpus. Used in BM25_docVec().\n",
    "N = indexReader.numDocs()\n",
    "avgdl_collection = indexReader.getSumTotalTermFreq(FIELDNAME)/N\n",
    "\n",
    "\n",
    "def tf_idf_query(term, query_terms):\n",
    "    # returns TF-IDF weight for the given term in query\n",
    "    D = len(query_terms)\n",
    "    N = indexReader.numDocs()\n",
    "    tf = query_terms.count(term)\n",
    "    df = indexReader.docFreq(Term(FIELDNAME, term))\n",
    "    weight = (tf/D)*(math.log(N/(df+1)))\n",
    "    return weight\n",
    "\n",
    "\n",
    "def tf_idf_docVec(docVec, D):\n",
    "    # tf-idf weight calculation for all the terms in the document vector\n",
    "    N = indexReader.numDocs()       # no. of total docs in the corpus\n",
    "    for t in docVec:\n",
    "        tf = docVec[t][0]\n",
    "        df = docVec[t][1]\n",
    "        idf = math.log(N/(df+1))\n",
    "        docVec[t] = (tf/D)*idf\n",
    "    \n",
    "    return docVec\n",
    "\n",
    "\n",
    "def BM25_query(term, query_terms, k1=0.8, b=0.4):\n",
    "    # returns Okapi BM25 weight for the given term in query\n",
    "    D = len(query_terms)\n",
    "    N = indexReader.numDocs()\n",
    "    tf = query_terms.count(term)\n",
    "    df = indexReader.docFreq(Term(FIELDNAME, term))\n",
    "    idf = math.log(1+((N-df+0.5)/(df+0.5)))\n",
    "    weight = ((tf*(1+k1))/(tf+k1*((1-b)+(b*D/avgdl_query))))*idf\n",
    "    return weight\n",
    "\n",
    "\n",
    "def BM25_docVec(docVec, D, k1=0.8, b=0.4):\n",
    "    # Okapi BM25 weight calculation for all the terms in the document vector\n",
    "    N = indexReader.numDocs()       # no. of total docs in the corpus\n",
    "    for t in docVec:\n",
    "        tf = docVec[t][0]\n",
    "        df = docVec[t][1]\n",
    "        idf = math.log(1+((N-df+0.5)/(df+0.5)))\n",
    "        docVec[t] = ((tf*(1+k1))/(tf+k1*((1-b)+(b*D/avgdl_collection))))*idf\n",
    "    \n",
    "    return docVec\n",
    "\n",
    "\n",
    "def getDocumentVector(luceneDocid, weightScheme):\n",
    "    # returns document vector in dictionary form with tf-idf weights\n",
    "    from org.apache.lucene.util import BytesRefIterator\n",
    "    \n",
    "    docVec = {}                     # doc vector, which will have terms as keys and \n",
    "                                    # its tf-idf weight in the doc as values\n",
    "    \n",
    "    D = 0                           # doc length, i.e., total no. of tokens in the doc\n",
    "    terms = indexReader.getTermVector(luceneDocid, FIELDNAME)\n",
    "    iterator = terms.iterator()\n",
    "    for term in BytesRefIterator.cast_(iterator):\n",
    "        t = term.utf8ToString()\n",
    "        tf = iterator.totalTermFreq()    # termFreq of term,t\n",
    "        df = indexReader.docFreq(Term(FIELDNAME, t))    # docFreq of term,t\n",
    "        D += tf\n",
    "        docVec[t] = [tf,df]\n",
    "        \n",
    "    if weightScheme == 'TFIDF':\n",
    "        docVec = tf_idf_docVec(docVec, D)\n",
    "    elif weightScheme == 'BM25':\n",
    "        docVec = BM25_docVec(docVec, D)\n",
    "    \n",
    "    return docVec\n",
    "\n",
    "\n",
    "def rocchio_PRF(query, top_k_docs, N, alpha, beta, weightScheme):\n",
    "    \"\"\"Implements Rocchio's relevance feedback and returns a modified query\n",
    "\n",
    "    Args:\n",
    "        query (org.apache.lucene.search.Query): lucene parsed version of the initial/original query\n",
    "        top_k_docs (lucene._lucene.JArray_object): scoreDocs returned after performing search with top k results\n",
    "        N (int): number of terms to be in the returned modified query\n",
    "        alpha (float): weight for original query\n",
    "        beta (float): weight for positive feedback\n",
    "        weightScheme (string): TFIDF or BM25 for term weighting\n",
    "\n",
    "    Returns:\n",
    "        list: expanded/modified query list of string query terms\n",
    "    \"\"\"\n",
    "    \n",
    "    # processing JQuery object to extract query terms in form of a list\n",
    "    query_terms = [term.strip()[len(FIELDNAME)+1:] for term in query.toString().split()]\n",
    "    \n",
    "    # creating query vector Q0\n",
    "    Q0_vector = {}\n",
    "    for term in query_terms:\n",
    "        if weightScheme == 'TFIDF':\n",
    "            Q0_vector[term] = tf_idf_query(term, query_terms)\n",
    "        elif weightScheme == 'BM25':\n",
    "            Q0_vector[term] = BM25_query(term, query_terms)\n",
    "    \n",
    "    sumRelDocsVector = {}     # Rel for Relevant, NRel for Non-relevant\n",
    "    numRel = 0\n",
    "    for scoreDoc in top_k_docs:\n",
    "        docVec = getDocumentVector(scoreDoc.doc, weightScheme)\n",
    "        numRel += 1\n",
    "        # vector addition of sumRelDocsVector and docVec\n",
    "        for term in docVec:\n",
    "            if term in sumRelDocsVector:\n",
    "                sumRelDocsVector[term] += docVec[term]\n",
    "            else:\n",
    "                sumRelDocsVector[term] = docVec[term]\n",
    "    \n",
    "    \n",
    "    r = {term: sumRelDocsVector[term]/numRel for term in sumRelDocsVector}    # normlaized Relevant Docs Vector\n",
    "    \n",
    "    # final Rocchio formula for Qm \n",
    "    expanded_query = [[term, alpha*Q0_vector.get(term,0) + beta*r.get(term,0)] for term in set(Q0_vector) | set(r)]\n",
    "    \n",
    "    expanded_query.sort(key = lambda x: x[1], reverse=True)   # sorted (descending) the expanded query list as per term scores\n",
    "    Qm_with_scores = expanded_query[:int(N)]     # selecting top N expanded query terms\n",
    "    \n",
    "    # weighting expanded query terms\n",
    "    booleanQuery = BooleanQuery.Builder()\n",
    "    for item in Qm_with_scores:\n",
    "        t = Term(FIELDNAME, item[0])\n",
    "        tq = TermQuery(t)\n",
    "        boostedTermQuery = BoostQuery(tq, item[1])\n",
    "        BooleanQuery.setMaxClauseCount(4096)\n",
    "        booleanQuery.add(boostedTermQuery, BooleanClause.Occur.SHOULD)\n",
    "    modifiedQuery = booleanQuery.build()\n",
    "    \n",
    "    return modifiedQuery   # modified query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMJM + Rocchio Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lmjm_rocchio(numPRD, N, alpha, beta, weightScheme='TFIDF'):\n",
    "    \"\"\" Performs LMJM search with Rocchio pseudo relevance feedback \n",
    "        on a set of queries and output the result in a file\n",
    "\n",
    "    Args:\n",
    "        numPRD: no. of pseudo relevant docs\n",
    "        N: no. of expansion terms\n",
    "        alpha, beta: Rocchio model parameters\n",
    "        weightScheme (string): TFIDF or BM25 for term weighting\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "     \n",
    "    \n",
    "    model = 'lmjm'\n",
    "    LAMBDA = 0.4   # LM-JM baseline lambda parameter\n",
    "    similarityModel = LMJelinekMercerSimilarity(LAMBDA)\n",
    "\n",
    "    # change result file path below\n",
    "    if weightScheme == 'BM25' or weightScheme == 'TFIDF':\n",
    "        rocchioOutputPath = f\"./Rocchio_output/{weightScheme}/LMJM_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta={beta}_{weightScheme}.res\"\n",
    "    else:\n",
    "        print('Warning: weightScheme entered not a valid parameter value. Taking default weightScheme: TFIDF')\n",
    "        weightScheme = 'TFIDF'\n",
    "        rocchioOutputPath = f\"./Rocchio_output/{weightScheme}/LMJM_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta={beta}_{weightScheme}.res\"\n",
    "    \n",
    "    f = open(rocchioOutputPath, 'w')\n",
    "\n",
    "    # setting up the searcher\n",
    "    analyzer = EnglishAnalyzer()    # used same analyzer as indexer\n",
    "    index_path = './index/'\n",
    "    directory = FSDirectory.open(File(index_path).toPath())\n",
    "    searcher = IndexSearcher(DirectoryReader.open(directory))\n",
    "    # setting the similarity model\n",
    "    searcher.setSimilarity(similarityModel)\n",
    "\n",
    "    print('\\nRetrieving ...')\n",
    "\n",
    "    # search on 50 queries from the topic file 'trec6.xml'\n",
    "    for topic in topics:\n",
    "        qidField = 'num'\n",
    "        queryKeywordsField = 'title'     # other fields are 'desc'and 'narr'\n",
    "\n",
    "        qid = topic.find(qidField).text.strip()\n",
    "        q = topic.find(queryKeywordsField).text.strip()\n",
    "\n",
    "        escaped_q = QueryParser(FIELDNAME, analyzer).escape(q)      # a few titles had '/' in them which \n",
    "                                                                    # EnglishAnalyzer was not able to parse\n",
    "                                                                    # without escaping those special characters\n",
    "        query = QueryParser(FIELDNAME, analyzer).parse(escaped_q)\n",
    "\n",
    "        print(f'Rocchio {weightScheme}, numPRD = {numPRD}, N = {N}, alpha = {alpha}, beta = {beta}; qid = {qid}, retrieving & writing ...', end=' ')\n",
    "\n",
    "        # getting the top pseudo relevant docs using the searcher\n",
    "        scoreDocs = searcher.search(query, numPRD).scoreDocs\n",
    "\n",
    "        # Rocchio expanded query retrieval\n",
    "        modified_query = rocchio_PRF(query, scoreDocs, N=N, alpha=alpha, beta=beta, weightScheme=weightScheme)\n",
    "\n",
    "        # getting the top k search results using the searcher\n",
    "        k = 1000\n",
    "        scoreDocs = searcher.search(modified_query, k).scoreDocs\n",
    "\n",
    "        # writing all k doc results in a .res file in TREC format\n",
    "        rank = 0\n",
    "        results = ''\n",
    "        for scoreDoc in scoreDocs:\n",
    "            rank += 1\n",
    "            doc = searcher.doc(scoreDoc.doc)\n",
    "            # f.write(f\"{qid}\\tQ0\\t{doc.get('DOCID')}\\t{rank}\\t{scoreDoc.score}\\taman_lmjm_{LAMBDA}-rocchio_{alpha}_{beta}\\n\")\n",
    "            results += f\"{qid}\\tQ0\\t{doc.get('DOCID')}\\t{rank}\\t{scoreDoc.score}\\taman_lmjm_{LAMBDA}-rocchio_{alpha}_{beta}\\n\"\n",
    "        \n",
    "        f.write(results)\n",
    "\n",
    "        print('complete!')\n",
    "\n",
    "    f.close()\n",
    "    print('Search completed! Search results exported to a .res file in the current directory.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding max MAP for LMJM+Rocchio-TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numPRD = 35\n",
    "# N = 100\n",
    "# alpha = 1\n",
    "# beta = 30\n",
    "\n",
    "# lmjm_rocchio(numPRD=numPRD,N=N,alpha=alpha,beta=beta, weightScheme='BM25')\n",
    "# lmjm_rocchio(numPRD=numPRD,N=N,alpha=alpha,beta=beta, weightScheme='TFIDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def getBetaForTopMAPs(beta_list, top):\n",
    "    MAPs = []\n",
    "    \n",
    "    for beta in beta_list:\n",
    "        rocchioOutputPath = f\"./Rocchio_output/{weightScheme}/LMJM_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta={beta}_{weightScheme}.res\"\n",
    "        result = subprocess.run(['trec_eval', 'trec678_robust.qrel', rocchioOutputPath], stdout=subprocess.PIPE)\n",
    "        shell_output_string = result.stdout.decode('utf-8')\n",
    "        if shell_output_string.split()[15] == 'map':\n",
    "            map_value = float(shell_output_string.split()[17])\n",
    "            MAPs.append([numPRD,N,alpha,beta,map_value])\n",
    "        else:\n",
    "            raise Exception('map_value index misalignment')\n",
    "    \n",
    "    MAPs.sort(key = lambda x: x[4], reverse=True)\n",
    "    \n",
    "    top_betas = []\n",
    "    top_MAPs = set()\n",
    "    counter = 0\n",
    "    for item in MAPs:\n",
    "        top_betas.append(item[3])\n",
    "        if item[4] not in top_MAPs:\n",
    "            counter += 1\n",
    "            top_MAPs.add(item[4])\n",
    "        if counter >= top:\n",
    "            break\n",
    "        \n",
    "    return top_betas\n",
    "\n",
    "\n",
    "def beta_loop():\n",
    "    beta_step_size = 10\n",
    "    min_beta_step_size = 2.5\n",
    "    beta_list = list(range(5,46,beta_step_size))\n",
    "    for beta in beta_list:\n",
    "        if f'LMJM_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta={beta}_{weightScheme}.res' not in os.listdir(f'./Rocchio_output/{weightScheme}/'):\n",
    "            lmjm_rocchio(numPRD=numPRD,N=N,alpha=alpha,beta=beta,weightScheme=weightScheme)\n",
    "    beta_step_size /= 2\n",
    "    while beta_step_size >= min_beta_step_size:\n",
    "        top_betas = getBetaForTopMAPs(beta_list, top=3)\n",
    "        beta_list = []\n",
    "        for beta in top_betas:\n",
    "            beta_list.append(beta+beta_step_size)\n",
    "            beta_list.append(beta-beta_step_size)\n",
    "        beta_list = sorted(list(set(beta_list)))\n",
    "        for beta in beta_list:\n",
    "            if f'LMJM_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta={beta}_{weightScheme}.res' not in os.listdir(f'./Rocchio_output/{weightScheme}/'):\n",
    "                lmjm_rocchio(numPRD=numPRD,N=N,alpha=alpha,beta=beta,weightScheme=weightScheme)\n",
    "        beta_step_size /= 2\n",
    "\n",
    "\n",
    "def getNforTopMAPs(N_list, top):\n",
    "    maxMAPs = []\n",
    "    \n",
    "    for N in N_list:\n",
    "        MAPs = []\n",
    "        for rocchioOutputPath in os.listdir(f'./Rocchio_output/{weightScheme}/'):\n",
    "            if rocchioOutputPath.startswith(f'LMJM_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta='):\n",
    "                result = subprocess.run(['trec_eval', 'trec678_robust.qrel', f'./Rocchio_output/{weightScheme}/'+rocchioOutputPath], stdout=subprocess.PIPE)\n",
    "                shell_output_string = result.stdout.decode('utf-8')\n",
    "                if shell_output_string.split()[15] == 'map':\n",
    "                    map_value = float(shell_output_string.split()[17])\n",
    "                    MAPs.append([numPRD,N,alpha,beta,map_value])\n",
    "                else:\n",
    "                    raise Exception('map_value index misalignment')\n",
    "        maxMAPs.append([N,max(MAPs, key=lambda x:x[4])[4]])\n",
    "    \n",
    "    maxMAPs.sort(key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_Ns = []\n",
    "    top_MAPs = set()\n",
    "    counter = 0\n",
    "    for item in maxMAPs:\n",
    "        top_Ns.append(item[0])\n",
    "        if item[1] not in top_MAPs:\n",
    "            counter += 1\n",
    "            top_MAPs.add(item[1])\n",
    "        if counter >= top:\n",
    "            break\n",
    "    \n",
    "    return top_Ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm for making lmjm_rocchio runs for all the appropriate params\n",
    "\n",
    "weightScheme = 'TFIDF'\n",
    "alpha = 1\n",
    "\n",
    "numPRD_step_size = 5\n",
    "for numPRD in range(20,46,numPRD_step_size):\n",
    "    N_step_size = 10\n",
    "    N_list = list(range(50,161,N_step_size))\n",
    "    for N in N_list:\n",
    "        beta_loop()\n",
    "    top_Ns = getNforTopMAPs(N_list,top=5)      # func considers max MAP for each N for choosing top Ns\n",
    "    N_list = []\n",
    "    N_step_size /= 2\n",
    "    for N in top_Ns:\n",
    "        N_list.append(N+N_step_size)\n",
    "        N_list.append(N-N_step_size)\n",
    "    N_list = sorted(list(set(N_list)))\n",
    "    for N in N_list:\n",
    "        beta_loop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating MAPs for all the 1893 lmjm_rochhio runs\n",
    "\n",
    "import subprocess\n",
    "import csv\n",
    "\n",
    "def paramsFromFilename(filename):\n",
    "    split_list = filename.split('_')\n",
    "    numPRD = int(split_list[2].split('=')[1])\n",
    "    N = int(float(split_list[3].split('=')[1]))\n",
    "    alpha = float(split_list[4].split('=')[1])\n",
    "    beta = float(split_list[5].split('=')[1])\n",
    "    return numPRD,N,alpha,beta\n",
    "\n",
    "f = open(f'./Rocchio_output/params_vs_MAP_Rocchio_{weightScheme}.tsv', 'w')\n",
    "tsv_writer = csv.writer(f, delimiter='\\t')\n",
    "tsv_writer.writerow(['method','numPRD','N','alpha','beta','MAP'])\n",
    "\n",
    "MAPs = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "sorted_filenames  = sorted(os.listdir(f'./Rocchio_output/{weightScheme}/'), key=paramsFromFilename)\n",
    "for filename in sorted_filenames:\n",
    "    numPRD,N,alpha,beta = paramsFromFilename(filename)\n",
    "    rocchioOutputPath = f'./Rocchio_output/{weightScheme}/' + filename\n",
    "    result = subprocess.run(['trec_eval', 'trec678_robust.qrel', rocchioOutputPath], stdout=subprocess.PIPE)\n",
    "    shell_output_string = result.stdout.decode('utf-8')\n",
    "    if shell_output_string.split()[15] == 'map':\n",
    "        map_value = float(shell_output_string.split()[17])\n",
    "        MAPs.append([numPRD,N,alpha,beta,map_value])\n",
    "        tsv_writer.writerow(['lmjm_0.4_rocchio_TFIDF',numPRD, N, alpha, beta, map_value])\n",
    "        counter += 1\n",
    "        print(f'{counter} ... done!')\n",
    "    else:\n",
    "        raise Exception('map_value index misalignment')\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 115, 1.0, 20.0, 0.2834]\n",
      "max MAP = 0.2834, for numPRD = 35, N = 115, alpha = 1.0, beta = 20.0\n"
     ]
    }
   ],
   "source": [
    "# highest MAP value and corresponding params\n",
    "\n",
    "res = max(MAPs, key=lambda x:x[4])\n",
    "print(res)\n",
    "print(f'max MAP = {res[4]}, for numPRD = {res[0]}, N = {res[1]}, alpha = {res[2]}, beta = {res[3]}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
